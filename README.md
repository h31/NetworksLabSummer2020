# Crawler

## Параметры запуска 

Файл: <b> MyCrawler/main.py </b>

Параметры командной строки:
* Название проекта (папки, в которой будут файлы с очередью и уже проработанными ссылками)
* URL домашней страницы сайта, который необходимо "пробежать"

<b> Пример запуска: </b>

NAME OF PROJECT: Коронавирус

HOMEPAGE URL: https://xn--80aesfpfapfkv.xn--p1ai/

<b> При запуске для удобства в консоль выводится следующая информация: </b>
    * Какой паук (поток) занят каким сайтом
    * Размер очереди (сколько ссылок ещё надо просмотреть)
    * Сколько ссылок уже просмотрено

## Форматы конфигурационных файлов

### Конфигурация Crawler'a

     NAME_OF_PROJECT: 
     HOMEPAGE_URL: 
     DOMAIN_NAME: 
     SPIDERS_NUMBER:

 | Параметр          | Описание                                                                               |
 |:------------------|:---------------------------------------------------------------------------------------|
 | NAME_OF_PROJECT   | Название папки с текстовыми файлами                                                    |
 | HOMEPAGE_URL      | URL домашней страницы сайта                                                            |
 | DOMAIN_NAME       | Доменное имя (чтобы не пробегать посторонние сайты, на которые есть ссылки на домашнем |
 | SPIDERS_NUMBER    | Количество потоков (пауков-работяг)                                                    |
 
 ### Файлы со ссылками в очереди и с уже проработанными ссылками
 
    Имена файлов собираются автоматически из названия проекта (папки) по следующему правилу:
    
      * QUEUE_FILE = NAME_OF_PROJECT + '/queue.txt'
      * CRAWLED_FILE = NAME_OF_PROJECT + '/crawled.txt'
     

